# 15DaysofML
This repository is a smaller version of [100DaysofML](https://github.com/kabirnagpal/100DaysofML) to motivate beginners to take up that challenge and dive deeper into the domain of Machine Learning.  

1. Worked with [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) and [XGBoost](https://xgboost.readthedocs.io/en/latest/) for a private anomaly detection dataset. [F1 - Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) was found to be around 96%.  
2. Worked on Data Visualisations using [Pairplot](https://seaborn.pydata.org/generated/seaborn.pairplot.html) and [Distplot](https://seaborn.pydata.org/generated/seaborn.distplot.html) to test Hypothesis and measure Skewness. Also worked on increasing Correalation of X with Y.  
3. Worked on [Feature extractions](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) for decreasing time consumed to train the model. Models used  
    - [recursive feature elimination](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE)
    - [f_classif](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif)
    - [mutual_info_classif](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif)
    - [SelectFromModel](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel)  
4. Worked with [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html) on the dataset and finetuned to reach an F1-score of 96.2% on an anomalies detection dataset.
5. Worked on reducing [skewness](https://towardsdatascience.com/transforming-skewed-data-73da4c2d0d16) of the dataset. Also worked with [Power Tranform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer) and understood the working. 
    - Right skewed: log transform
    - Left skewed : square transform
6. Learned EDA technique and and new types of graphs in [Sea Born](https://seaborn.pydata.org/) like swarmplot, KDE etc.
7. Half way through writing research paper, learned about [ResNet](https://keras.io/api/applications/resnet/#resnet50-function) in depth, learned [BoxCox](https://www.geeksforgeeks.org/box-cox-transformation-using-python/) for reducing skewness.
8. Tried a skewness reduction method on [Pet Adoption data](https://www.hackerearth.com/challenges/competitive/hackerearth-machine-learning-challenge-pet-adoption/leaderboard/pet-adoption-9-5838c75b/). Learned more about hypothesis and P-value.
9. After multiple tests on Training set, I applied the mehtods to test datatset. Sadly the accuracy achieved was only 88%. Worked more on hypothesis understanding. 
10. Researched about autocorrect methods using Deep Learning and distance method.  
11. Trying to implement [Bi Directional LSTM](https://keras.io/api/layers/recurrent_layers/bidirectional/)
12. Back to basics for Multilayer perceptron from scratch. Associative Network trial in Matlab
13. Recieved Assignment related to geospatial data for internship. Data Analysis + Classification
14. Read and understood these research paper
    - [Ensemble Stacked CNN for ESC](https://pdfs.semanticscholar.org/94bb/f0223b4c7dcaa0ff4f9a52c8558591d2f611.pdf?_ga=2.46438254.857111201.1598176321-200861282.1591779849)
    - [MFCC and GMM](https://www.researchgate.net/publication/261423419_Gender_identification_of_a_speaker_using_MFCC_and_GMM/citations
)
